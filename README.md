# infra2csv - Infrastructure Data Collection to CSV

A minimal, robust Ansible collection for gathering system infrastructure data and exporting it to CSV. Built for automation, audits, and analytics pipelines â€” from Power BI dashboards to compliance reports.

Created by **Nasi Alsahli**  
ğŸ™ Thanks to Red Hat and AI tech for making this easier.

---

## ğŸ”¥ Features

- âœ… **Resilient**: Handles broken commands and distro quirks
- ğŸ›  **Centralized Utils**: Reusable logic in `module_utils`
- ğŸ“‹ **Schema Validation**: Uniform CSV structure
- ğŸ” **Check Mode**: Preview data without writing
- ğŸ“¦ **Complete Coverage**: Hardware, network, storage, users, security, fs health
- ğŸ“Š **Output Options**: CSV or table format
- ğŸš€ **Production Ready**: Clean, tested, and structured

---

## ğŸ“¦ Modules

| Module             | Purpose                                                  |
|--------------------|----------------------------------------------------------|
| `hardware_csv`     | System-level hardware details                            |
| `network_csv`      | Network interfaces, MACs, state, MTU                     |
| `storage_csv`      | Filesystem usage + block devices (dual mode)             |
| `users_csv`        | Users, logins, cron, sudo                                |
| `security_baseline`| SELinux, firewalld, SSH, sudoers                         |
| `filesystem_health`| fsck status and ext/XFS health checks                    |

---

## ğŸ“Š Output Formats

| Option   | Description                               | Default |
|----------|-------------------------------------------|---------|
| `csv`    | Structured CSV to the path you set        | âœ…      |
| `table`  | Pretty table printed to stdout            |         |

```yaml
- name: Preview hardware info in console
  crusty_rs.infra2csv.hardware_csv:
    output_format: table

## ğŸ§¬ CSV Schema Fields

| Module              | Fields |
|---------------------|--------|
| `hardware_csv`      | hostname, ip, os, os_version, arch, cpu, ram_gb, uptime_sec, boot_time, serial_number, model, cpu_cores, cpu_threads, disk_total_gb, user_count, run_by, timestamp |
| `network_csv`       | interface, mac_address, state, speed_mbps, mtu, hostname, run_by, timestamp |
| `storage_csv (fs)`  | mode, device, type, size, used, avail, use_percent, mountpoint, hostname, run_by, timestamp |
| `storage_csv (dev)` | mode, device, size_bytes, type, model, hostname, run_by, timestamp |
| `users_csv`         | hostname, username, uid, gid, home_directory, shell, last_login, schedule, command, source_type, enabled, next_run_time, timestamp, is_privileged |
| `security_baseline` | hostname, selinux_status, firewalld_status, ssh_root_login, password_auth_status, users_with_sudo, timestamp |
| `filesystem_health` | hostname, mountpoint, fsck_required, last_fsck, last_fsck_result, filesystem_type, timestamp |

---

## ğŸ“ Directory Layout

collections/
â””â”€â”€ ansible_collections/
â””â”€â”€ crusty_rs/
â””â”€â”€ infra2csv/
â”œâ”€â”€ plugins/
â”‚ â”œâ”€â”€ modules/
â”‚ â”‚ â””â”€â”€ *.py
â”‚ â””â”€â”€ module_utils/
â”‚ â””â”€â”€ infra2csv_utils.py
â””â”€â”€ README.md

--

## â–¶ï¸ Example Usage

```yaml
- name: Collect Infrastructure Data
  hosts: all
  become: true
  tasks:
    - name: Collect hardware info
      crusty_rs.infra2csv.hardware_csv:
        csv_path: /var/lib/infra2csv/hardware.csv

## ğŸ§  Tips & Best Practices

- Run with `become: true` â€” most modules need elevated access to gather system-level data.
- Use tools like Power BI or Excel to visualize and explore your infrastructure â€” great for insights, though adds extra tooling overhead.
- Separate CSV files by data type â€” easier to manage and analyze, but requires coordination when merging for unified views.
- Schedule periodic runs with `cron` or `systemd` â€” automates your data pipeline, but adds complexity to your ops stack.
- Rotate or archive old CSV logs â€” avoids disk bloat, though youâ€™ll need a retention policy and storage strategy.
---

## ğŸ§© Creator & Thanks

**Creator:** Yasir Hamadi Alsahli  
**Thanks:** Red Hat & open AI tools for dev acceleration

